{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSuzhuRwo57a",
        "outputId": "9f3e8cdc-af1b-48f4-f706-4f47a6de6986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8UQR18pq_4a",
        "outputId": "562b4222-ffc0-4bac-f236-4875e1812aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 781, done.\u001b[K\n",
            "remote: Total 781 (delta 0), reused 0 (delta 0), pack-reused 781 (from 1)\u001b[K\n",
            "Receiving objects: 100% (781/781), 3.27 MiB | 40.34 MiB/s, done.\n",
            "Resolving deltas: 100% (331/331), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov9.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zpYmhDfFPPU",
        "outputId": "3e688ba4-93e6-4019-edd1-65e9cc5938b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.47-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Downloading roboflow-1.1.47-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, idna, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.47\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "/content/yolov9\n",
            "visit https://app.roboflow.com/auth-cli to get your authentication token.\n",
            "Paste the authentication token here: ··········\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in cabbage-segment-1 to yolov9:: 100%|██████████| 110622/110622 [00:01<00:00, 58378.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to cabbage-segment-1 in yolov9:: 100%|██████████| 2208/2208 [00:00<00:00, 2411.61it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import roboflow\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Show GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Set current directory\n",
        "os.chdir('/content')\n",
        "%cd yolov9\n",
        "\n",
        "roboflow.login()\n",
        "\n",
        "rf = roboflow.Roboflow()\n",
        "\n",
        "project = rf.workspace(\"deeplearning-bhinb\").project(\"cabbage-segment-iuyzz\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov9\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python segment/train.py \\\n",
        "--workers 8 \\\n",
        "--device 0 \\\n",
        "--batch 16  \\\n",
        "--data {dataset.location}/data.yaml \\\n",
        "--img 512 \\\n",
        "--cfg models/segment/gelan-c-seg.yaml \\\n",
        "--weights '' \\\n",
        "--name gelan-c-seg \\\n",
        "--optimizer 'Adam' \\\n",
        "--hyp hyp.scratch-high.yaml \\\n",
        "--no-overlap \\\n",
        "--epochs 50 \\\n",
        "--close-mosaic 10"
      ],
      "metadata": {
        "id": "KbGvlmUfTchn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245d3a0f-e554-4a62-ff51-165d58f54a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-04 03:27:21.178141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-04 03:27:21.199106: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-04 03:27:21.205454: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-04 03:27:21.220608: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-04 03:27:22.395323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1msegment/train: \u001b[0mweights=, cfg=models/segment/gelan-c-seg.yaml, data=/content/yolov9/cabbage-segment-1/data.yaml, hyp=hyp.scratch-high.yaml, epochs=50, batch_size=16, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=Adam, sync_bn=False, workers=8, project=runs/train-seg, name=gelan-c-seg, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, close_mosaic=10, mask_ratio=4, no_overlap=True\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-seg', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 91.8MB/s]\n",
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            "  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            "  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            "  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
            " 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
            " 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
            " 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 22      [15, 18, 21]  1   7633547  models.yolo.Segment                     [9, 32, 256, [256, 512, 512]] \n",
            "gelan-c-seg summary: 657 layers, 27579979 parameters, 27579963 gradients\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01) with parameter groups 163 weight(decay=0.0), 173 weight(decay=0.0005), 172 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov9/cabbage-segment-1/train/labels... 962 images, 0 backgrounds, 0 corrupt: 100% 962/962 [00:00<00:00, 1541.63it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov9/cabbage-segment-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov9/cabbage-segment-1/valid/labels... 91 images, 0 backgrounds, 0 corrupt: 100% 91/91 [00:00<00:00, 1157.86it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov9/cabbage-segment-1/valid/labels.cache\n",
            "Plotting labels to runs/train-seg/gelan-c-seg/labels.jpg... \n",
            "/content/yolov9/segment/train.py:236: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Image sizes 512 train, 512 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train-seg/gelan-c-seg\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/61 [00:00<?, ?it/s]/content/yolov9/segment/train.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/49      10.1G      4.237      5.387      4.657      4.215       1357        512:   2% 1/61 [00:08<08:12,  8.22s/it]Exception in thread Thread-11 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "       0/49      11.6G       4.23      5.761      4.683      4.199       1609        512:   3% 2/61 [00:09<03:47,  3.86s/it]Exception in thread Thread-12 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "       0/49      11.6G      4.214      5.337      4.687      4.204       1482        512:   5% 3/61 [00:09<02:22,  2.46s/it]Exception in thread Thread-13 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "       0/49      11.9G      3.626      2.118      3.558      3.011        171        512: 100% 61/61 [00:56<00:00,  1.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:06<00:00,  2.24s/it]\n",
            "                   all         91       3415          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/49      11.9G      2.858       1.41      2.952      2.146        120        512: 100% 61/61 [00:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:06<00:00,  2.30s/it]\n",
            "                   all         91       3415     0.0133      0.131     0.0089    0.00264    0.00422     0.0322    0.00205   0.000482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/49      11.9G      2.566      1.381      2.825       1.96        143        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:06<00:00,  2.24s/it]\n",
            "                   all         91       3415      0.079      0.124     0.0473     0.0199     0.0911      0.133     0.0542     0.0136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/49      11.9G      2.369      1.343      2.695      1.857        124        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:05<00:00,  1.72s/it]\n",
            "                   all         91       3415      0.574     0.0754     0.0661     0.0329      0.366      0.118     0.0705     0.0258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/49      14.4G      2.235       1.31      2.599      1.768         60        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:04<00:00,  1.63s/it]\n",
            "                   all         91       3415     0.0915      0.295      0.093     0.0391     0.0871       0.28     0.0808     0.0259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/49      14.4G      2.195        1.3      2.576      1.731        190        512: 100% 61/61 [00:49<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.24s/it]\n",
            "                   all         91       3415      0.113      0.244      0.116     0.0538      0.114      0.245      0.116     0.0434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/49      12.1G      2.102      1.302      2.497      1.678        262        512: 100% 61/61 [00:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.22s/it]\n",
            "                   all         91       3415     0.0853      0.565      0.131     0.0668     0.0717      0.489       0.11     0.0382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/49      12.1G      2.004      1.275      2.361      1.652        172        512: 100% 61/61 [00:50<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         91       3415      0.105      0.796      0.195      0.102        0.1      0.756      0.184     0.0743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/49      14.6G      1.982      1.253      2.335      1.665         68        512: 100% 61/61 [00:50<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.11s/it]\n",
            "                   all         91       3415      0.298       0.42      0.195      0.108      0.293      0.406      0.187     0.0734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/49      14.6G      1.905      1.237      2.248      1.586        123        512: 100% 61/61 [00:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.18s/it]\n",
            "                   all         91       3415      0.189      0.422      0.243      0.128      0.191      0.413      0.242      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/49      14.6G      1.892      1.227      2.229      1.568         43        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.20s/it]\n",
            "                   all         91       3415      0.248      0.278       0.22      0.113      0.248       0.26      0.207     0.0766\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/49      14.6G      1.873      1.229       2.19      1.595        106        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:06<00:00,  2.13s/it]\n",
            "                   all         91       3415       0.05     0.0453     0.0218    0.00887      0.054     0.0425     0.0223    0.00519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/49      14.6G      1.841      1.205      2.142      1.559        104        512: 100% 61/61 [00:50<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.12s/it]\n",
            "                   all         91       3415      0.186      0.508      0.236      0.136      0.188      0.474      0.225     0.0835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/49      14.6G       1.84      1.203      2.166      1.569        180        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:04<00:00,  1.36s/it]\n",
            "                   all         91       3415       0.21      0.479      0.229      0.134      0.208      0.448       0.22     0.0901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/49      14.6G      1.758      1.166      2.086      1.512         98        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:04<00:00,  1.36s/it]\n",
            "                   all         91       3415      0.338      0.389       0.27      0.154      0.339      0.381      0.268      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/49      14.6G      1.788      1.167      2.059      1.549         56        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.22s/it]\n",
            "                   all         91       3415      0.157      0.586      0.243      0.143      0.154      0.586      0.231     0.0973\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/49      14.6G      1.691      1.124      1.989      1.488         91        512: 100% 61/61 [00:50<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.14s/it]\n",
            "                   all         91       3415        0.3      0.517      0.341      0.197      0.301      0.506      0.336      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/49      14.6G       1.67      1.128       1.98      1.498         85        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:04<00:00,  1.38s/it]\n",
            "                   all         91       3415      0.244      0.525      0.318      0.175      0.241      0.509      0.305      0.121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/49      14.6G      1.676      1.112      1.937      1.472        144        512: 100% 61/61 [00:50<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.12s/it]\n",
            "                   all         91       3415      0.332      0.552      0.373      0.217      0.322      0.539      0.355       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/49      14.6G      1.643      1.081      1.877      1.465        204        512: 100% 61/61 [00:49<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.03it/s]\n",
            "                   all         91       3415       0.37      0.545      0.384      0.224      0.353      0.515      0.352      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/49      14.6G      1.654      1.086      1.871      1.456        140        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.03s/it]\n",
            "                   all         91       3415      0.315      0.471      0.364      0.214      0.312      0.454      0.352      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/49      14.6G      1.629      1.069      1.878      1.454         86        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.04s/it]\n",
            "                   all         91       3415      0.303      0.473      0.335      0.207        0.3      0.458      0.327      0.147\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/49      14.6G      1.623      1.051      1.819      1.478         71        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.03it/s]\n",
            "                   all         91       3415      0.323      0.557      0.369      0.237      0.321      0.547       0.36      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/49      14.6G      1.615      1.052      1.817      1.436         98        512: 100% 61/61 [00:49<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.01s/it]\n",
            "                   all         91       3415      0.276      0.502      0.348      0.215      0.278      0.488      0.337      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/49      14.6G      1.582      1.036      1.745      1.422        217        512: 100% 61/61 [00:51<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.01it/s]\n",
            "                   all         91       3415      0.319      0.624      0.409      0.255      0.315      0.618      0.399      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/49      14.6G      1.572       1.04       1.73      1.416        220        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         91       3415      0.487      0.528      0.479      0.307      0.492      0.514      0.469      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/49      14.6G      1.544      1.026      1.771      1.417        216        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.06s/it]\n",
            "                   all         91       3415       0.31      0.521      0.448      0.293      0.314      0.502      0.437      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/49      14.6G      1.513     0.9915      1.705      1.402         49        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.02it/s]\n",
            "                   all         91       3415      0.415      0.581      0.495       0.32       0.41      0.569      0.482      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/49      14.6G      1.524     0.9946      1.708      1.426         74        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.02s/it]\n",
            "                   all         91       3415      0.484      0.513      0.497      0.322      0.479      0.507      0.489      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/49      14.6G      1.505     0.9989      1.661       1.39        297        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.00s/it]\n",
            "                   all         91       3415      0.514      0.618      0.547      0.364      0.512      0.606      0.534      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/49      14.6G      1.489     0.9753      1.637      1.399        170        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.18s/it]\n",
            "                   all         91       3415      0.451      0.604      0.505      0.333      0.449      0.596      0.499      0.251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/49      14.6G      1.511     0.9924      1.628      1.414        154        512: 100% 61/61 [00:50<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         91       3415       0.56      0.632      0.607      0.395       0.55      0.624      0.595      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/49      14.6G       1.47     0.9679       1.58      1.388        219        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.01s/it]\n",
            "                   all         91       3415      0.471      0.616      0.493      0.339      0.467      0.609      0.486      0.248\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/49      14.6G       1.45     0.9543      1.575      1.384        120        512: 100% 61/61 [00:50<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         91       3415      0.528      0.608      0.566      0.371      0.518      0.591      0.549      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/49      14.6G      1.438     0.9521      1.546      1.376        166        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         91       3415      0.471      0.659      0.587      0.398      0.463      0.648       0.57      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/49      14.6G      1.428     0.9295      1.513      1.369         47        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.01it/s]\n",
            "                   all         91       3415      0.421      0.612      0.498      0.342      0.416      0.609      0.487      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/49      14.6G      1.436     0.9338      1.544       1.38        217        512: 100% 61/61 [00:50<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.01s/it]\n",
            "                   all         91       3415      0.424      0.671      0.567      0.386      0.419      0.644      0.554      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/49      14.6G       1.41     0.9187      1.459      1.358         69        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.02it/s]\n",
            "                   all         91       3415      0.596      0.664      0.652      0.451      0.592      0.657       0.64       0.34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/49      14.6G      1.385     0.9044      1.449      1.336        189        512: 100% 61/61 [00:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.02it/s]\n",
            "                   all         91       3415       0.62      0.688      0.678      0.462      0.614      0.682      0.666      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/49      14.6G      1.425      0.919      1.443      1.358        357        512: 100% 61/61 [00:51<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.03it/s]\n",
            "                   all         91       3415      0.605      0.654      0.661      0.457      0.601      0.648      0.651      0.359\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/49      14.6G      1.221     0.8713      1.419      1.353         56        512: 100% 61/61 [00:41<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.07it/s]\n",
            "                   all         91       3415      0.411      0.605      0.533      0.365      0.407      0.597      0.525      0.274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/49      14.6G      1.188       0.85      1.385      1.353         61        512: 100% 61/61 [00:41<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.07it/s]\n",
            "                   all         91       3415      0.359       0.61      0.455      0.305      0.356      0.599      0.452      0.247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/49      14.6G      1.214     0.8666      1.413      1.335         79        512: 100% 61/61 [00:41<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         91       3415      0.565      0.638      0.654      0.456      0.563      0.628      0.643      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/49      14.6G      1.163     0.8187      1.294      1.331         71        512: 100% 61/61 [00:41<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         91       3415      0.591      0.692      0.683      0.476      0.587      0.681      0.673      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/49      14.6G      1.151     0.8151      1.263      1.323         65        512: 100% 61/61 [00:41<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         91       3415      0.527      0.587      0.591      0.417      0.515      0.583      0.579      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/49      14.6G      1.118     0.8067      1.194        1.3         64        512: 100% 61/61 [00:41<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.09it/s]\n",
            "                   all         91       3415      0.551      0.649      0.598       0.43      0.543      0.647      0.588      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/49      14.6G      1.113     0.7945      1.203      1.294         79        512: 100% 61/61 [00:41<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         91       3415      0.637      0.677      0.697      0.499      0.633      0.668      0.684      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/49      14.6G      1.109     0.7756      1.212      1.275         44        512: 100% 61/61 [00:41<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         91       3415      0.675      0.731      0.752      0.542      0.672      0.715       0.74      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/49      14.6G      1.106     0.7781      1.161      1.299         99        512: 100% 61/61 [00:41<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.09it/s]\n",
            "                   all         91       3415      0.599      0.751        0.7      0.505       0.59      0.742      0.691      0.411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/49      14.6G      1.079     0.7506      1.099      1.279         47        512: 100% 61/61 [00:42<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.03it/s]\n",
            "                   all         91       3415      0.674      0.744      0.749      0.537      0.669      0.735      0.736      0.435\n",
            "\n",
            "50 epochs completed in 0.757 hours.\n",
            "/content/yolov9/utils/general.py:999: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x = torch.load(f, map_location=torch.device('cpu'))\n",
            "Optimizer stripped from runs/train-seg/gelan-c-seg/weights/last.pt, 55.7MB\n",
            "Optimizer stripped from runs/train-seg/gelan-c-seg/weights/best.pt, 55.7MB\n",
            "\n",
            "Validating runs/train-seg/gelan-c-seg/weights/best.pt...\n",
            "/content/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c-seg summary: 414 layers, 27369067 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  33% 1/3 [00:01<00:02,  1.21s/it]Exception in thread Thread-64 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "Exception in thread Thread-63 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  67% 2/3 [00:02<00:01,  1.21s/it]Exception in thread Thread-66 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "Exception in thread Thread-65 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.14s/it]\n",
            "Exception in thread Thread-68 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "Exception in thread Thread-67 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "                   all         91       3415      0.676      0.731      0.752      0.543      0.673      0.714      0.741      0.442\n",
            "         OkinaSP-Kaizu         91        399      0.712      0.762      0.837      0.667      0.717      0.739      0.823       0.56\n",
            "      OkinaSP-Sunomata         91        763      0.739      0.805      0.787      0.526      0.738      0.798       0.78      0.412\n",
            "          OkinaSP-Yoro         91        361      0.561      0.484      0.511      0.356      0.551      0.446      0.503       0.28\n",
            "       RedCabbage-Yoro         91        106       0.94      0.738      0.813      0.568      0.904      0.708      0.774      0.448\n",
            "         Suiryoku-Yoro         91        312      0.504      0.635       0.64      0.503      0.511      0.619      0.633      0.425\n",
            "          TCA422-Kaizu         91        557      0.782      0.916      0.911      0.622      0.786      0.916      0.912      0.545\n",
            "       TCA422-Sunomata         91        355      0.559      0.654      0.689      0.514      0.567      0.648      0.683       0.42\n",
            "        Yumebutai-Yoro         91        562      0.607      0.856       0.83      0.586       0.61      0.842      0.816      0.445\n",
            "Warning: Plotting error for runs/train-seg/gelan-c-seg/results.csv: 'value' must be an instance of str or bytes, not a float\n",
            "Results saved to \u001b[1mruns/train-seg/gelan-c-seg\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "!unzip /content/drive/MyDrive/model_adamw.zip -d /content/yolov9/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5HskqnPoHpj",
        "outputId": "b5c5ae4d-a069-4d80-e50d-5ac789e11216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/model_adamw.zip\n",
            "   creating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/\n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/labels_correlogram.jpg  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/hyp.yaml  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/MaskPR_curve.png  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/opt.yaml  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/BoxF1_curve.png  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/labels.jpg  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/MaskP_curve.png  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/events.out.tfevents.1728098984.0a48a5b04bef.3839.0  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/results.csv  \n",
            "   creating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/weights/\n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/weights/last.pt  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/weights/best.pt  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/results.png  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/BoxPR_curve.png  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/confusion_matrix.png  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/BoxP_curve.png  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/BoxR_curve.png  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/MaskF1_curve.png  \n",
            "  inflating: /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/MaskR_curve.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov9/segment/val.py \\\n",
        "--data /content/yolov9/cabbage-segment-1/data.yaml \\\n",
        "--imgsz 512 \\\n",
        "--device cpu \\\n",
        "--weights /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/weights/best.pt \\\n",
        "--name gelan_c_c_512_detect_v1 \\\n",
        "--task test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP8lVYd2jL8G",
        "outputId": "8acfee24-7761-493b-b62c-b689cf74ac55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1msegment/val: \u001b[0mdata=/content/yolov9/cabbage-segment-1/data.yaml, weights=['/content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/weights/best.pt'], batch_size=32, imgsz=512, conf_thres=0.001, iou_thres=0.6, max_det=300, task=test, device=cpu, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val-seg, name=gelan_c_c_512_detect_v1, exist_ok=False, half=False, dnn=False\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.10.12 torch-2.4.1+cu121 CPU\n",
            "\n",
            "/content/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c-seg summary: 414 layers, 27369067 parameters, 0 gradients\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 83.9MB/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning /content/yolov9/cabbage-segment-1/test/labels... 45 images, 0 backgrounds, 0 corrupt: 100% 45/45 [00:00<00:00, 763.67it/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /content/yolov9/cabbage-segment-1/test/labels.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50% 1/2 [00:31<00:31, 32.00s/it]Exception in thread Thread-6 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "Exception in thread Thread-5 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 2/2 [00:42<00:00, 21.46s/it]\n",
            "Exception in thread Thread-8 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "                   all         45       1682      0.722       0.78      0.823      0.591      0.721      0.757      0.809      0.453\n",
            "         OkinaSP-Kaizu         45        232      0.687      0.888      0.858      0.661      0.671      0.849      0.814      0.454\n",
            "      OkinaSP-Sunomata         45        280      0.761      0.786      0.782      0.516      0.763      0.764      0.766      0.362\n",
            "          OkinaSP-Yoro         45        217      0.755        0.7      0.797      0.527      0.752      0.668      0.768      0.345\n",
            "       RedCabbage-Yoro         45         34          1      0.985      0.995      0.664          1      0.978      0.995      0.559\n",
            "         Suiryoku-Yoro         45        138      0.634      0.551      0.696      0.582      0.639      0.529      0.692      0.479\n",
            "          TCA422-Kaizu         45        324      0.825      0.969      0.968      0.663      0.826       0.96      0.963      0.553\n",
            "       TCA422-Sunomata         45        210      0.638      0.671      0.768      0.569      0.651      0.662      0.768      0.482\n",
            "        Yumebutai-Yoro         45        247      0.478      0.692      0.723      0.544      0.467      0.648      0.705      0.389\n",
            "Speed: 21.2ms pre-process, 822.9ms inference, 6.6ms NMS per image at shape (32, 3, 512, 512)\n",
            "Exception in thread Thread-7 (plot_images_and_masks):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/segment/plots.py\", line 81, in plot_images_and_masks\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "Results saved to \u001b[1mruns/val-seg/gelan_c_c_512_detect_v1\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python segment/predict.py \\\n",
        "--source /content/yolov9/cabbage-segment-1/test/images \\\n",
        "--img 512 --device cpu \\\n",
        "--weights /content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/weights/best.pt \\\n",
        "--name gelan_c_c_512_detect_v1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvueUC3WvEeJ",
        "outputId": "609c90fa-eec7-49a3-fa1f-9f394fd1b11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1msegment/predict: \u001b[0mweights=['/content/yolov9/content/yolov9/runs/train-seg/gelan-c-seg/weights/best.pt'], source=/content/yolov9/cabbage-segment-1/test/images, data=data/coco128.yaml, imgsz=[512, 512], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=cpu, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/predict-seg, name=gelan_c_c_512_detect_v1, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1, retina_masks=False\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLO requirements \"gitpython\" \"ipython\" not found, attempting AutoUpdate...\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 14.9 MB/s eta 0:00:00\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 4.0 MB/s eta 0:00:00\n",
            "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, jedi, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 jedi-0.19.1 smmap-5.0.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per /content/yolov9/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.10.12 torch-2.4.1+cu121 CPU\n",
            "\n",
            "/content/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c-seg summary: 414 layers, 27369067 parameters, 0 gradients\n",
            "image 1/45 /content/yolov9/cabbage-segment-1/test/images/img004_20201027_Kaizu_TCA422_515x515_png.rf.99667cd29d2038060c83c32f5a641244.jpg: 512x512 1 OkinaSP-Kaizu, 29 TCA422-Kaizus, 853.2ms\n",
            "image 2/45 /content/yolov9/cabbage-segment-1/test/images/img015_20201027_Kaizu_TCA422_515x515_png.rf.8905c4cb908cb1c7d1520a2268603b84.jpg: 512x512 29 TCA422-Kaizus, 787.1ms\n",
            "image 3/45 /content/yolov9/cabbage-segment-1/test/images/img016_20201027_Kaizu_TCA422_515x515_png.rf.d5237908bbb022e55b483436528d778b.jpg: 512x512 32 TCA422-Kaizus, 771.2ms\n",
            "image 4/45 /content/yolov9/cabbage-segment-1/test/images/img029_20201027_Kaizu_TCA422_515x515_png.rf.fe95c1697e4b350932998397ab0d7348.jpg: 512x512 32 TCA422-Kaizus, 784.7ms\n",
            "image 5/45 /content/yolov9/cabbage-segment-1/test/images/img045_20201027_Kaizu_OkinaSP_515x515_png.rf.4d09c2fb3ff4d8f398c9e3b0f08341dd.jpg: 512x512 24 OkinaSP-Kaizus, 11 TCA422-Kaizus, 572.6ms\n",
            "image 6/45 /content/yolov9/cabbage-segment-1/test/images/img061_20201027_Kaizu_TCA422_515x515_png.rf.f7fc3559fbc21e8f7a7985854474c804.jpg: 512x512 18 TCA422-Kaizus, 549.9ms\n",
            "image 7/45 /content/yolov9/cabbage-segment-1/test/images/img064_20201027_Kaizu_TCA422_515x515_png.rf.0faced044756fea4b71e9e0e279a9174.jpg: 512x512 33 TCA422-Kaizus, 555.2ms\n",
            "image 8/45 /content/yolov9/cabbage-segment-1/test/images/img079_20201027_Kaizu_TCA422_515x515_png.rf.2adfd2149e56512fec27199a60b399fc.jpg: 512x512 36 TCA422-Kaizus, 539.3ms\n",
            "image 9/45 /content/yolov9/cabbage-segment-1/test/images/img090_20201027_Kaizu_TCA422_900x900_png.rf.1892333bc9f2581938e6bb5652b624bb.jpg: 512x512 82 TCA422-Kaizus, 559.7ms\n",
            "image 10/45 /content/yolov9/cabbage-segment-1/test/images/img102_20201027_Kaizu_TCA422_900x900_png.rf.de2a3847a1a5f76b3e45f71cdb27022e.jpg: 512x512 86 TCA422-Kaizus, 554.2ms\n",
            "image 11/45 /content/yolov9/cabbage-segment-1/test/images/img118_20210916_Sunomata_TCA422_550x550_png.rf.ffb97d760c049df1697ff58f859faa2f.jpg: 512x512 12 OkinaSP-Sunomatas, 545.3ms\n",
            "image 12/45 /content/yolov9/cabbage-segment-1/test/images/img120_20210916_Sunomata_TCA422_550x550_png.rf.c52b73da67ef95d2696fa5db5347ed96.jpg: 512x512 14 OkinaSP-Sunomatas, 543.3ms\n",
            "image 13/45 /content/yolov9/cabbage-segment-1/test/images/img123_20210916_Sunomata_OkinaSP_550x550_png.rf.8b62bbe1c70a37eb701fb1f1bcf141a1.jpg: 512x512 18 OkinaSP-Sunomatas, 556.1ms\n",
            "image 14/45 /content/yolov9/cabbage-segment-1/test/images/img134_20211126_Sunomata_OkinaSP_550x550_png.rf.4a88a1ae3612b37bf43c3a1699733ff2.jpg: 512x512 15 OkinaSP-Sunomatas, 2 TCA422-Kaizus, 3 TCA422-Sunomatas, 550.9ms\n",
            "image 15/45 /content/yolov9/cabbage-segment-1/test/images/img135_20211126_Sunomata_OkinaSP_550x550_png.rf.7b745a970dedb8ae55b8b69b6a82b7fc.jpg: 512x512 18 OkinaSP-Sunomatas, 5 TCA422-Sunomatas, 557.1ms\n",
            "image 16/45 /content/yolov9/cabbage-segment-1/test/images/img142_20210907_Kaizu_OkinaSP_1000x1000_png.rf.f5f700389aaca5a824cb426123b1e766.jpg: 512x512 39 OkinaSP-Kaizus, 4 Yumebutai-Yoros, 576.7ms\n",
            "image 17/45 /content/yolov9/cabbage-segment-1/test/images/img170_20210921_Yoro_Yumebutai_1000x1000_png.rf.43b734585331210d2d4aa26cc70957d1.jpg: 512x512 1 OkinaSP-Kaizu, 40 Yumebutai-Yoros, 548.0ms\n",
            "image 18/45 /content/yolov9/cabbage-segment-1/test/images/img171_20210921_Yoro_Suiryoku_1000x1000_png.rf.7dff950ab981ddefaa9e09372b4c198d.jpg: 512x512 1 OkinaSP-Sunomata, 8 Suiryoku-Yoros, 40 Yumebutai-Yoros, 551.1ms\n",
            "image 19/45 /content/yolov9/cabbage-segment-1/test/images/img173_20210921_Yoro_Suiryoku_1000x1000_png.rf.70ebd3c3d9c55c2387c302dc3e5df873.jpg: 512x512 1 OkinaSP-Yoro, 9 Suiryoku-Yoros, 41 Yumebutai-Yoros, 796.7ms\n",
            "image 20/45 /content/yolov9/cabbage-segment-1/test/images/img176_20210921_Yoro_OkinaSP_1000x1000_png.rf.cdd2f57381e40ac1aa97891b3bdf26ed.jpg: 512x512 40 OkinaSP-Kaizus, 8 Yumebutai-Yoros, 914.1ms\n",
            "image 21/45 /content/yolov9/cabbage-segment-1/test/images/img200_20210927_Yoro_OkinaSP_1000x1000_png.rf.51780012ecd0546b67c7784ccd2e8bce.jpg: 512x512 34 OkinaSP-Yoros, 32 Yumebutai-Yoros, 729.4ms\n",
            "image 22/45 /content/yolov9/cabbage-segment-1/test/images/img201_20210927_Yoro_Yumebutai_1000x1000_png.rf.639b8995cd70021278218c998179e28b.jpg: 512x512 4 OkinaSP-Yoros, 42 Yumebutai-Yoros, 542.3ms\n",
            "image 23/45 /content/yolov9/cabbage-segment-1/test/images/img203_20211005_Kaizu_OkinaSP_1000x1000_png.rf.bbbe47ad2bc95fe42ddcbd73ef12ab1d.jpg: 512x512 42 OkinaSP-Kaizus, 2 Yumebutai-Yoros, 542.2ms\n",
            "image 24/45 /content/yolov9/cabbage-segment-1/test/images/img204_20211005_Kaizu_OkinaSP_1000x1000_png.rf.f95631335020449af897557e66f48d1e.jpg: 512x512 25 OkinaSP-Kaizus, 8 Yumebutai-Yoros, 549.4ms\n",
            "image 25/45 /content/yolov9/cabbage-segment-1/test/images/img213_20211005_Sunomata_OkinaSP_1000x1000_png.rf.f4708f2ebccfdd1924aee6a49d1bcfc6.jpg: 512x512 35 OkinaSP-Sunomatas, 24 TCA422-Sunomatas, 1 Yumebutai-Yoro, 554.2ms\n",
            "image 26/45 /content/yolov9/cabbage-segment-1/test/images/img226_20211005_Yoro_OkinaSP_1000x1000_png.rf.bdd19fde0e31188773179b16e4689de1.jpg: 512x512 17 OkinaSP-Kaizus, 36 OkinaSP-Yoros, 18 Yumebutai-Yoros, 551.6ms\n",
            "image 27/45 /content/yolov9/cabbage-segment-1/test/images/img245_20211011_Yoro_Suiryoku_1000x1000_png.rf.1bd0bcf64131a11576f92fc167bdc24c.jpg: 512x512 6 OkinaSP-Yoros, 43 Suiryoku-Yoros, 26 Yumebutai-Yoros, 549.1ms\n",
            "image 28/45 /content/yolov9/cabbage-segment-1/test/images/img247_20211011_Yoro_OkinaSP_1000x1000_png.rf.4024f24c34d693d01b26341819ceb3d9.jpg: 512x512 1 OkinaSP-Sunomata, 41 OkinaSP-Yoros, 1 Suiryoku-Yoro, 5 Yumebutai-Yoros, 556.8ms\n",
            "image 29/45 /content/yolov9/cabbage-segment-1/test/images/img249_20211011_Yoro_Yumebutai_1000x1000_png.rf.8c2bd99c3b9a9770b8c5c7f2ce8d4ebe.jpg: 512x512 13 OkinaSP-Yoros, 2 Suiryoku-Yoros, 47 Yumebutai-Yoros, 549.7ms\n",
            "image 30/45 /content/yolov9/cabbage-segment-1/test/images/img253_20211018_Kaizu_OkinaSP_1000x1000_png.rf.81eee77a497305d4d7b34145ae1d6d5f.jpg: 512x512 31 OkinaSP-Kaizus, 555.9ms\n",
            "image 31/45 /content/yolov9/cabbage-segment-1/test/images/img260_20211018_Sunomata_OkinaSP_1000x1000_png.rf.c5b29e5d15f357c288fa07ee7adab632.jpg: 512x512 25 OkinaSP-Sunomatas, 37 TCA422-Sunomatas, 3 Yumebutai-Yoros, 535.8ms\n",
            "image 32/45 /content/yolov9/cabbage-segment-1/test/images/img268_20211018_Yoro_Yumebutai_1000x1000_png.rf.ed22a1206d8bf12b56a91df2974785d5.jpg: 512x512 1 OkinaSP-Yoro, 32 Yumebutai-Yoros, 536.3ms\n",
            "image 33/45 /content/yolov9/cabbage-segment-1/test/images/img282_20211027_Kaizu_OkinaSP_1000x1000_png.rf.68983d66f0de3c718cd94e8ab5fe5a87.jpg: 512x512 21 OkinaSP-Kaizus, 552.0ms\n",
            "image 34/45 /content/yolov9/cabbage-segment-1/test/images/img286_20211027_Sunomata_TCA422_1000x1000_png.rf.58ef7fdead8436c6f3c5e27362736bbe.jpg: 512x512 3 OkinaSP-Sunomatas, 53 TCA422-Sunomatas, 698.4ms\n",
            "image 35/45 /content/yolov9/cabbage-segment-1/test/images/img306_20211109_Kaizu_OkinaSP_1000x1000_png.rf.8868f43bd79e2202166dea300740a546.jpg: 512x512 40 OkinaSP-Kaizus, 766.7ms\n",
            "image 36/45 /content/yolov9/cabbage-segment-1/test/images/img309_20211109_Sunomata_OkinaSP_1000x1000_png.rf.76ce7c4ce3a0068a950c406afc634a3b.jpg: 512x512 31 OkinaSP-Sunomatas, 9 TCA422-Sunomatas, 781.8ms\n",
            "image 37/45 /content/yolov9/cabbage-segment-1/test/images/img333_20211114_Yoro_OkinaSP_1000x1000_png.rf.56cc2d433762ff284f84e7e349e9b388.jpg: 512x512 49 OkinaSP-Yoros, 1 Suiryoku-Yoro, 3 Yumebutai-Yoros, 823.4ms\n",
            "image 38/45 /content/yolov9/cabbage-segment-1/test/images/img347_20211126_Sunomata_TCA422_1000x1000_png.rf.0c245a14a514d9d87367e798ebfc74c0.jpg: 512x512 2 OkinaSP-Sunomatas, 51 TCA422-Sunomatas, 568.0ms\n",
            "image 39/45 /content/yolov9/cabbage-segment-1/test/images/img348_20220909_Yoro_Yumebutai_1000x1000_png.rf.735b7787495721f524c6b796c56c8cd0.jpg: 512x512 12 OkinaSP-Yoros, 32 Suiryoku-Yoros, 14 Yumebutai-Yoros, 540.9ms\n",
            "image 40/45 /content/yolov9/cabbage-segment-1/test/images/img365_20220909_Yoro_Yumebutai_1000x1000_png.rf.c8ff1541799f02acc09ec5116d354e91.jpg: 512x512 14 OkinaSP-Yoros, 20 Suiryoku-Yoros, 15 Yumebutai-Yoros, 535.3ms\n",
            "image 41/45 /content/yolov9/cabbage-segment-1/test/images/img373_20220910_Sunomata_OkinaSP_1000x1000_png.rf.5ca3c3366fdd7eb1ab3f78c33e6c8ec8.jpg: 512x512 49 OkinaSP-Sunomatas, 532.0ms\n",
            "image 42/45 /content/yolov9/cabbage-segment-1/test/images/img385_20220926_Sunomata_OkinaSP_1000x1000_png.rf.9e30cb83665f6a49436c86934232b883.jpg: 512x512 43 OkinaSP-Sunomatas, 5 TCA422-Sunomatas, 556.5ms\n",
            "image 43/45 /content/yolov9/cabbage-segment-1/test/images/img410_20221021_Sunomata_TCA422_1000x1000_png.rf.b2281ac1e5c5ae9dc25343be00777d37.jpg: 512x512 1 OkinaSP-Kaizu, 13 OkinaSP-Sunomatas, 15 TCA422-Kaizus, 6 TCA422-Sunomatas, 4 Yumebutai-Yoros, 551.0ms\n",
            "image 44/45 /content/yolov9/cabbage-segment-1/test/images/img414_20221021_Sunomata_TCA422_1000x1000_png.rf.0b2051d450ffbf47272ede05ab4b9380.jpg: 512x512 11 OkinaSP-Sunomatas, 43 TCA422-Sunomatas, 536.2ms\n",
            "image 45/45 /content/yolov9/cabbage-segment-1/test/images/img435_20221121_Yoro_RedCabbage_1000x1000_png.rf.d0ad04b18d5009811cbc6fb8840cd5a4.jpg: 512x512 34 RedCabbage-Yoros, 549.1ms\n",
            "Speed: 0.5ms pre-process, 609.1ms inference, 1.2ms NMS per image at shape (1, 3, 512, 512)\n",
            "Results saved to \u001b[1mruns/predict-seg/gelan_c_c_512_detect_v1\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive('gelan_c_c_512_detect_v3', 'zip', '/content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v3')\n",
        "\n",
        "files.download('gelan_c_c_512_detect_v3.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YqrZ16xFpXX8",
        "outputId": "69e2dabb-ecc1-4b29-be0b-75492cf0bd95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4487c030-2711-4510-a41f-f28684b2981b\", \"gelan_c_c_512_detect_v3.zip\", 11193497)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxumWCwfrx5x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "!rm -rf yolov9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "98Q1xopeWTSe",
        "outputId": "142e9fea-2a04-4e5a-af15-63b6cf24e620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/yolov9/runs/ (stored 0%)\n",
            "  adding: content/yolov9/runs/predict-seg/ (stored 0%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/ (stored 0%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img173_20210921_Yoro_Suiryoku_1000x1000_png.rf.70ebd3c3d9c55c2387c302dc3e5df873.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img016_20201027_Kaizu_TCA422_515x515_png.rf.d5237908bbb022e55b483436528d778b.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img204_20211005_Kaizu_OkinaSP_1000x1000_png.rf.f95631335020449af897557e66f48d1e.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img306_20211109_Kaizu_OkinaSP_1000x1000_png.rf.8868f43bd79e2202166dea300740a546.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img079_20201027_Kaizu_TCA422_515x515_png.rf.2adfd2149e56512fec27199a60b399fc.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img015_20201027_Kaizu_TCA422_515x515_png.rf.8905c4cb908cb1c7d1520a2268603b84.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img170_20210921_Yoro_Yumebutai_1000x1000_png.rf.43b734585331210d2d4aa26cc70957d1.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img309_20211109_Sunomata_OkinaSP_1000x1000_png.rf.76ce7c4ce3a0068a950c406afc634a3b.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img348_20220909_Yoro_Yumebutai_1000x1000_png.rf.735b7787495721f524c6b796c56c8cd0.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img203_20211005_Kaizu_OkinaSP_1000x1000_png.rf.bbbe47ad2bc95fe42ddcbd73ef12ab1d.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img142_20210907_Kaizu_OkinaSP_1000x1000_png.rf.f5f700389aaca5a824cb426123b1e766.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img414_20221021_Sunomata_TCA422_1000x1000_png.rf.0b2051d450ffbf47272ede05ab4b9380.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img201_20210927_Yoro_Yumebutai_1000x1000_png.rf.639b8995cd70021278218c998179e28b.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img064_20201027_Kaizu_TCA422_515x515_png.rf.0faced044756fea4b71e9e0e279a9174.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img134_20211126_Sunomata_OkinaSP_550x550_png.rf.4a88a1ae3612b37bf43c3a1699733ff2.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img365_20220909_Yoro_Yumebutai_1000x1000_png.rf.c8ff1541799f02acc09ec5116d354e91.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img118_20210916_Sunomata_TCA422_550x550_png.rf.ffb97d760c049df1697ff58f859faa2f.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img347_20211126_Sunomata_TCA422_1000x1000_png.rf.0c245a14a514d9d87367e798ebfc74c0.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img004_20201027_Kaizu_TCA422_515x515_png.rf.99667cd29d2038060c83c32f5a641244.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img249_20211011_Yoro_Yumebutai_1000x1000_png.rf.8c2bd99c3b9a9770b8c5c7f2ce8d4ebe.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img282_20211027_Kaizu_OkinaSP_1000x1000_png.rf.68983d66f0de3c718cd94e8ab5fe5a87.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img120_20210916_Sunomata_TCA422_550x550_png.rf.c52b73da67ef95d2696fa5db5347ed96.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img253_20211018_Kaizu_OkinaSP_1000x1000_png.rf.81eee77a497305d4d7b34145ae1d6d5f.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img245_20211011_Yoro_Suiryoku_1000x1000_png.rf.1bd0bcf64131a11576f92fc167bdc24c.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img373_20220910_Sunomata_OkinaSP_1000x1000_png.rf.5ca3c3366fdd7eb1ab3f78c33e6c8ec8.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img200_20210927_Yoro_OkinaSP_1000x1000_png.rf.51780012ecd0546b67c7784ccd2e8bce.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img435_20221121_Yoro_RedCabbage_1000x1000_png.rf.d0ad04b18d5009811cbc6fb8840cd5a4.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img171_20210921_Yoro_Suiryoku_1000x1000_png.rf.7dff950ab981ddefaa9e09372b4c198d.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img410_20221021_Sunomata_TCA422_1000x1000_png.rf.b2281ac1e5c5ae9dc25343be00777d37.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img213_20211005_Sunomata_OkinaSP_1000x1000_png.rf.f4708f2ebccfdd1924aee6a49d1bcfc6.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img061_20201027_Kaizu_TCA422_515x515_png.rf.f7fc3559fbc21e8f7a7985854474c804.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img226_20211005_Yoro_OkinaSP_1000x1000_png.rf.bdd19fde0e31188773179b16e4689de1.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img102_20201027_Kaizu_TCA422_900x900_png.rf.de2a3847a1a5f76b3e45f71cdb27022e.jpg (deflated 0%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img268_20211018_Yoro_Yumebutai_1000x1000_png.rf.ed22a1206d8bf12b56a91df2974785d5.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img247_20211011_Yoro_OkinaSP_1000x1000_png.rf.4024f24c34d693d01b26341819ceb3d9.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img286_20211027_Sunomata_TCA422_1000x1000_png.rf.58ef7fdead8436c6f3c5e27362736bbe.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img123_20210916_Sunomata_OkinaSP_550x550_png.rf.8b62bbe1c70a37eb701fb1f1bcf141a1.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img135_20211126_Sunomata_OkinaSP_550x550_png.rf.7b745a970dedb8ae55b8b69b6a82b7fc.jpg (deflated 2%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img045_20201027_Kaizu_OkinaSP_515x515_png.rf.4d09c2fb3ff4d8f398c9e3b0f08341dd.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img385_20220926_Sunomata_OkinaSP_1000x1000_png.rf.9e30cb83665f6a49436c86934232b883.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img333_20211114_Yoro_OkinaSP_1000x1000_png.rf.56cc2d433762ff284f84e7e349e9b388.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img090_20201027_Kaizu_TCA422_900x900_png.rf.1892333bc9f2581938e6bb5652b624bb.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img029_20201027_Kaizu_TCA422_515x515_png.rf.fe95c1697e4b350932998397ab0d7348.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img260_20211018_Sunomata_OkinaSP_1000x1000_png.rf.c5b29e5d15f357c288fa07ee7adab632.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/predict-seg/gelan_c_c_512_detect_v1/img176_20210921_Yoro_OkinaSP_1000x1000_png.rf.cdd2f57381e40ac1aa97891b3bdf26ed.jpg (deflated 1%)\n",
            "  adding: content/yolov9/runs/val-seg/ (stored 0%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/ (stored 0%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/confusion_matrix.png (deflated 17%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/BoxR_curve.png (deflated 6%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/BoxPR_curve.png (deflated 9%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/MaskPR_curve.png (deflated 7%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/MaskR_curve.png (deflated 5%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/BoxF1_curve.png (deflated 5%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/MaskF1_curve.png (deflated 4%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/MaskP_curve.png (deflated 5%)\n",
            "  adding: content/yolov9/runs/val-seg/gelan_c_c_512_detect_v1/BoxP_curve.png (deflated 6%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6c73eced-3d1a-47bd-9276-598313512337\", \"model.zip\", 13821219)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Zip the model directory\n",
        "!zip -r model.zip /content/yolov9/runs/\n",
        "\n",
        "# Download the zip file\n",
        "files.download(\"model.zip\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}